{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b056af8-77ef-452b-8efa-9951c60e0b9e",
   "metadata": {},
   "source": [
    "# **Project Name**  - Vaccination Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e187d846-292a-4d43-be91-87415c55d5f8",
   "metadata": {},
   "source": [
    "##### **Project Type**   - Python,SQL,EDA,Power BI\n",
    "##### **Contribution**   - Individual\n",
    "##### **Team Member 1 -**  Gade Pavan Kumar Reddy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614610d8-fd66-4cf0-97d8-f0ed11bda91f",
   "metadata": {},
   "source": [
    "# **Project Summary -**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89735196-e486-4d65-bbde-73b09fdd196a",
   "metadata": {},
   "source": [
    "This project centers on analyzing global vaccination and infectious disease data to support better public health decisions. By designing and implementing a structured MySQL database, we integrated diverse datasets covering vaccination coverage, disease incidence, vaccine schedules, and country-level details. The cleaned and transformed data—comprising hundreds of thousands of records—are loaded into a relational database and connected to Power BI for advanced analytics and visualization.\r\n",
    "\r\n",
    "Using Power BI, we developed interactive dashboards that enable users to explore trends in vaccination rates and disease incidence, uncover regional disparities, and evaluate the effectiveness of immunization programs. Scatter plots reveal the relationship between vaccination coverage and disease reduction, while geographical heatmaps identify regions of concern and progress. Trend lines, KPI indicators, and slicers facilitate dynamic filtering by year, country, or disease, making the analysis accessible and actionable for health officials and policymakers.\r\n",
    "\r\n",
    "The solution supports scenario-based investigations—such as tracking the impact of new vaccine introductions, identifying regions for resource allocation, and monitoring progress toward international immunization targets. The system is set up for scheduled refreshes, ensuring that stakeholders always work with up-to-date information. This project offers a scalable and adaptable blueprint for turning raw health data into actionable insights, empowering public health interventions and resource prioritization for maximum impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b1d06b-6a6a-4bb0-974d-f1060de4a634",
   "metadata": {},
   "source": [
    "# **GitHub Link**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4ae7b-581d-4c77-9c03-bd0aa9532c8c",
   "metadata": {},
   "source": [
    "Link- https://github.com/pavangade31/Vaccination-data-and-visualization-project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15cdb6d-65e7-405a-8dc7-f219792aedb6",
   "metadata": {},
   "source": [
    "# **Problem Statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a6a0ec-e03d-4e99-afc5-d15d714656b6",
   "metadata": {},
   "source": [
    "Despite ongoing vaccination efforts, many regions face persistent challenges in achieving high immunization coverage and controlling vaccine-preventable diseases. Fragmented data sources and a lack of integrated analytical tools make it difficult for health agencies to identify coverage gaps, evaluate program effectiveness, and respond rapidly to emerging outbreaks. Without a centralized, real-time analysis platform, decision-makers struggle to understand where interventions are most needed and to monitor progress toward health objectives.\r\n",
    "\r\n",
    "This project addresses the need for an end-to-end data pipeline and interactive analytics—transforming disparate vaccination and disease data into unified, actionable dashboards to enable more targeted, effective public health decisions and interventions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257364cb-491e-4308-90ea-bde585ef8b30",
   "metadata": {},
   "source": [
    "# ***Let's Begin !***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801d1c22-5082-44c4-ac6a-13407bdc1b91",
   "metadata": {},
   "source": [
    "## Step 1: Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7321f0f5-ade0-466a-be2c-bd08e8d3f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine,text\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d183480-a84e-4249-b313-be90ef2b94e8",
   "metadata": {},
   "source": [
    "## Step 2: Load Excel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c3691d8-08e5-4190-a0fe-06edddf0276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df = pd.read_excel('coverage-data.xlsx')                  \n",
    "incidence_df = pd.read_excel('incidence-rate-data.xlsx')                \n",
    "cases_df = pd.read_excel('reported-cases-data.xlsx')                    \n",
    "intro_df = pd.read_excel('vaccine-introduction-data.xlsx')              \n",
    "schedule_df = pd.read_excel('vaccine-schedule-data.xlsx') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd2e22-3393-4ed6-b3fd-624fa3a17c83",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleaning and Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b121be7d-b5af-43ee-85ad-999ec2933483",
   "metadata": {},
   "source": [
    "### 3.1: Checking Shape of all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "761c5702-c996-460a-9090-d4ec2a86c39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of coverage_df:\n",
      "(399859, 11)\n",
      "---------------------------------------\n",
      "Shape of incidence_df:\n",
      "(84946, 8)\n",
      "---------------------------------------\n",
      "Shape of cases_df:\n",
      "(84870, 7)\n",
      "---------------------------------------\n",
      "Shape of intro_df:\n",
      "(138321, 6)\n",
      "---------------------------------------\n",
      "Shape of schedule_df:\n",
      "(8053, 12)\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dfs = {\n",
    "    \"coverage_df\": coverage_df,\n",
    "    \"incidence_df\": incidence_df,\n",
    "    \"cases_df\": cases_df,\n",
    "    \"intro_df\": intro_df,\n",
    "    \"schedule_df\": schedule_df\n",
    "}\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    print(f\"Shape of {name}:\")\n",
    "    print(df.shape)\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7625ffa4-c53d-4935-84aa-7e56dbcb7544",
   "metadata": {},
   "source": [
    "### 3.2: Checking Percentage of Missing Values in all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "045a9f65-f6a1-48b6-a3ee-abcbe873e86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values percentage for every column in coverage_df:\n",
      "GROUP                             0.000000\n",
      "CODE                              0.000250\n",
      "NAME                              0.318862\n",
      "YEAR                              0.000250\n",
      "ANTIGEN                           0.000250\n",
      "ANTIGEN_DESCRIPTION               0.000250\n",
      "COVERAGE_CATEGORY                 0.000250\n",
      "COVERAGE_CATEGORY_DESCRIPTION     0.000250\n",
      "TARGET_NUMBER                    80.235533\n",
      "DOSES                            80.161257\n",
      "COVERAGE                         42.360432\n",
      "dtype: float64\n",
      "---------------------------------------\n",
      "Missing values percentage for every column in incidence_df:\n",
      "GROUP                   0.000000\n",
      "CODE                    0.001177\n",
      "NAME                    0.001177\n",
      "YEAR                    0.001177\n",
      "DISEASE                 0.001177\n",
      "DISEASE_DESCRIPTION     0.001177\n",
      "DENOMINATOR             0.001177\n",
      "INCIDENCE_RATE         27.502178\n",
      "dtype: float64\n",
      "---------------------------------------\n",
      "Missing values percentage for every column in cases_df:\n",
      "GROUP                   0.000000\n",
      "CODE                    0.001178\n",
      "NAME                    0.001178\n",
      "YEAR                    0.001178\n",
      "DISEASE                 0.001178\n",
      "DISEASE_DESCRIPTION     0.001178\n",
      "CASES                  22.858489\n",
      "dtype: float64\n",
      "---------------------------------------\n",
      "Missing values percentage for every column in intro_df:\n",
      "ISO_3_CODE     0.000000\n",
      "COUNTRYNAME    0.000723\n",
      "WHO_REGION     0.000723\n",
      "YEAR           0.000723\n",
      "DESCRIPTION    0.000723\n",
      "INTRO          0.000723\n",
      "dtype: float64\n",
      "---------------------------------------\n",
      "Missing values percentage for every column in schedule_df:\n",
      "ISO_3_CODE                0.000000\n",
      "COUNTRYNAME               0.012418\n",
      "WHO_REGION                0.012418\n",
      "YEAR                      0.012418\n",
      "VACCINECODE               0.012418\n",
      "VACCINE_DESCRIPTION       0.012418\n",
      "SCHEDULEROUNDS            0.012418\n",
      "TARGETPOP                52.874705\n",
      "TARGETPOP_DESCRIPTION     0.012418\n",
      "GEOAREA                   0.384950\n",
      "AGEADMINISTERED          12.988948\n",
      "SOURCECOMMENT            36.185273\n",
      "dtype: float64\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, df in dfs.items():\n",
    "    print(f\"Missing values percentage for every column in {name}:\")\n",
    "    print(df.isna().mean()*100)\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73dc050-41d7-4e05-9066-4f3219217e00",
   "metadata": {},
   "source": [
    "### 3.3: Cleaning and Imputing Coverage Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65681468-1651-4175-8d0e-86420c5da6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = coverage_df.copy()\n",
    "df = df.drop(columns=['TARGET_NUMBER', 'DOSES'])\n",
    "\n",
    "# Impute 'NAME'\n",
    "df['NAME'] = df.groupby('CODE')['NAME'].transform(lambda x: x.ffill().bfill())\n",
    "df['NAME'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Function to impute with median only if median > 0, else keep NaN for second fill\n",
    "def impute_nonzero_median(x):\n",
    "    med = x.median()\n",
    "    if med > 0:\n",
    "        return x.fillna(med)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df['COVERAGE'] = df.groupby(['CODE', 'ANTIGEN'])['COVERAGE'].transform(impute_nonzero_median)\n",
    "\n",
    "# Fill remaining NaNs with overall median excluding zeros\n",
    "overall_median = df.loc[df['COVERAGE'] > 0, 'COVERAGE'].median()\n",
    "df['COVERAGE'] = df['COVERAGE'].fillna(overall_median)\n",
    "\n",
    "# Drop rows with any remaining missing data\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "coverage_df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f8476-cada-4b89-a3ae-f14ce886d683",
   "metadata": {},
   "source": [
    "**Remove**: **TARGET_NUMBER** (80.24% missing) and **DOSES** (80.16% missing) – too much missingness for reliable imputation.\n",
    "\r\n",
    "\r\n",
    "Impute: NAME (0.32%) with forward-fill/backward-fill by 'CODE'; COVERAGE (42.36%) with median by group (still valuable for correlation/trend\n",
    ").\r\n",
    "\r\n",
    "All other columns have negligible missingness—fill or drop remaining NaNs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ca2a33-3853-44ce-a9ca-3fe9d83e01ca",
   "metadata": {},
   "source": [
    "### 3.4: Cleaning and Imputing Incidence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7607403e-4d5f-4411-b939-3a980946778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cleaning incidence_df ---\n",
    "df_incidence = incidence_df.copy()\n",
    "\n",
    "# Fill 'NAME' missing by forward/backward fill within 'CODE'\n",
    "df_incidence['NAME'] = df_incidence.groupby('CODE')['NAME'].transform(lambda x: x.ffill().bfill())\n",
    "df_incidence['NAME'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Function to impute incidence_rate only if group's median > 0\n",
    "def impute_nonzero_median(x):\n",
    "    med = x.median()\n",
    "    if med > 0:\n",
    "        return x.fillna(med)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df_incidence['INCIDENCE_RATE'] = df_incidence.groupby('DISEASE')['INCIDENCE_RATE'].transform(impute_nonzero_median)\n",
    "\n",
    "# Fill remaining NaNs with overall median excluding zeros\n",
    "overall_median_incidence = df_incidence.loc[df_incidence['INCIDENCE_RATE'] > 0, 'INCIDENCE_RATE'].median()\n",
    "df_incidence['INCIDENCE_RATE'] = df_incidence['INCIDENCE_RATE'].fillna(overall_median_incidence)\n",
    "\n",
    "# Drop any rows still having missing values\n",
    "df_incidence.dropna(inplace=True)\n",
    "\n",
    "incidence_df_clean = df_incidence.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b6ae1a-88ee-4260-83de-5e2072b2b3a8",
   "metadata": {},
   "source": [
    "**Remove**: None—the only column with significant missingness is INCIDENCE_RATE (27.50%), still useful for analysis.\n",
    "\r\n",
    "\r\n",
    "Impute: INCIDENCE_RATE by median per 'DISEASE'; other columns use forward-fill/backward-fill by 'CODE'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512af0f3-def6-44b5-8357-cc11209356ac",
   "metadata": {},
   "source": [
    "### 3.5: Cleaning and Imputing Cases Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ba6a45c-f566-4c79-9ab7-53ecc281dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cleaning cases_df ---\n",
    "df_cases = cases_df.copy()\n",
    "\n",
    "# Fill 'NAME' missing by forward/backward fill within 'CODE'\n",
    "df_cases['NAME'] = df_cases.groupby('CODE')['NAME'].transform(lambda x: x.ffill().bfill())\n",
    "df_cases['NAME'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Impute CASES only if group's median > 0\n",
    "df_cases['CASES'] = df_cases.groupby('DISEASE')['CASES'].transform(impute_nonzero_median)\n",
    "\n",
    "# Fill remaining NaNs with overall median excluding zeros\n",
    "overall_median_cases = df_cases.loc[df_cases['CASES'] > 0, 'CASES'].median()\n",
    "df_cases['CASES'] = df_cases['CASES'].fillna(overall_median_cases)\n",
    "\n",
    "# Drop rows with missing data\n",
    "df_cases.dropna(inplace=True)\n",
    "\n",
    "cases_df_clean = df_cases.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe331e9b-1698-4eb4-b99f-bd98e3e9ca40",
   "metadata": {},
   "source": [
    "**Remove**: None—CASES missingness (22.86%) is high, but still usable for reduction analysis.\r\n",
    "\r\n",
    "Impute: CASES by median per 'DISEASE'; fill others as above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df144ae8-2188-497d-87a0-a19a92bdbcb9",
   "metadata": {},
   "source": [
    "### 3.6: Cleaning and Imputing Vaccine Introduction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45521dcc-448b-4237-9334-3ea187097ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = intro_df.copy()\n",
    "for col in ['COUNTRYNAME', 'WHO_REGION', 'YEAR', 'DESCRIPTION', 'INTRO']:\n",
    "    df[col] = df[col].ffill().bfill()\n",
    "df.dropna(inplace=True)\n",
    "intro_df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54820180-d9fc-49d9-b85f-7d05a170017a",
   "metadata": {},
   "source": [
    "**Remove/Impute**: Very low missingness (<1%); forward-fill/backward-fill all missing categorical columns (by 'ISO_3_CODE' or globally). Drop if any missing remain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71669ac8-19c3-4272-b03a-14b40f8b87ae",
   "metadata": {},
   "source": [
    "### 3.7: Cleaning and Imputing Schedule Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b9348d-0197-4c1c-bdf1-840e488745e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = schedule_df.copy()\n",
    "df = df.drop(columns=['TARGETPOP'])  # remove due to high missingness\n",
    "\n",
    "# Fill others by group\n",
    "for col in ['COUNTRYNAME', 'WHO_REGION', 'YEAR', 'VACCINECODE', 'VACCINE_DESCRIPTION', 'SCHEDULEROUNDS', 'TARGETPOP_DESCRIPTION', 'GEOAREA']:\n",
    "    df[col] = df.groupby('ISO_3_CODE')[col].transform(lambda x: x.ffill().bfill())\n",
    "# Impute AGEADMINISTERED and SOURCECOMMENT\n",
    "df['AGEADMINISTERED'].fillna('Not specified', inplace=True)\n",
    "df['SOURCECOMMENT'].fillna('No comment', inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "schedule_df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bbf3ce-2b69-4696-ae1b-66f9d6ba9a7c",
   "metadata": {},
   "source": [
    "**Remove**: TARGETPOP (52.87%)—over half missing, drop for robust analysis.\r\n",
    "\r\n",
    "Impute: AGEADMINISTERED (12.99%) and SOURCECOMMENT (36.19%)—impute missing values with placeholders; other columns impute by ffill/bfill by 'ISO_3_CODE'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c849b-a89e-473c-8ae3-650838eb3737",
   "metadata": {},
   "source": [
    "### 3.8: Changing 'YEAR' Column into Integer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5b3efad-c006-47e5-aadd-83c15289bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df_clean['YEAR'] = coverage_df_clean['YEAR'].astype(int)\n",
    "incidence_df_clean['YEAR'] = incidence_df_clean['YEAR'].astype(int)\n",
    "cases_df_clean['YEAR'] = cases_df_clean['YEAR'].astype(int)\n",
    "intro_df_clean['YEAR'] = intro_df_clean['YEAR'].astype(int)\n",
    "schedule_df_clean['YEAR'] = schedule_df_clean['YEAR'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39df3f46-aef1-4680-969b-f0455e1512b7",
   "metadata": {},
   "source": [
    "### 3.9: Checking the shape of Cleaned Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fd37100-82e3-4af6-9c72-111842841fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of coverage_df after cleaning and imputation:\n",
      "(399858, 9)\n",
      "---------------------------------------\n",
      "Shape of incidence_df after cleaning and imputation:\n",
      "(84945, 8)\n",
      "---------------------------------------\n",
      "Shape of cases_df after cleaning and imputation:\n",
      "(84869, 7)\n",
      "---------------------------------------\n",
      "Shape of intro_df after cleaning and imputation:\n",
      "(138321, 6)\n",
      "---------------------------------------\n",
      "Shape of schedule_df after cleaning and imputation:\n",
      "(8052, 11)\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dfs_new = {\n",
    "    \"coverage_df\": coverage_df_clean,\n",
    "    \"incidence_df\": incidence_df_clean,\n",
    "    \"cases_df\": cases_df_clean,\n",
    "    \"intro_df\": intro_df_clean,\n",
    "    \"schedule_df\": schedule_df_clean\n",
    "}\n",
    "\n",
    "for name, df in dfs_new.items():\n",
    "    print(f\"Shape of {name} after cleaning and imputation:\")\n",
    "    print(df.shape)\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca695a3d-11f2-44c9-8e01-79175277df7b",
   "metadata": {},
   "source": [
    "### 3.10: Checking Percentage of Missing Values in all Cleaned dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aa4b09f-1e9a-4a00-bc92-612963d9ac5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values percentage for every column in coverage_df after cleaning and imputation:\n",
      "GROUP                            0.0\n",
      "CODE                             0.0\n",
      "NAME                             0.0\n",
      "YEAR                             0.0\n",
      "ANTIGEN                          0.0\n",
      "ANTIGEN_DESCRIPTION              0.0\n",
      "COVERAGE_CATEGORY                0.0\n",
      "COVERAGE_CATEGORY_DESCRIPTION    0.0\n",
      "COVERAGE                         0.0\n",
      "dtype: float64\n",
      "---------------------------------------\n",
      "Missing values percentage for every column in incidence_df after cleaning and imputation:\n",
      "GROUP                  0.0\n",
      "CODE                   0.0\n",
      "NAME                   0.0\n",
      "YEAR                   0.0\n",
      "DISEASE                0.0\n",
      "DISEASE_DESCRIPTION    0.0\n",
      "DENOMINATOR            0.0\n",
      "INCIDENCE_RATE         0.0\n",
      "dtype: float64\n",
      "---------------------------------------\n",
      "Missing values percentage for every column in cases_df after cleaning and imputation:\n",
      "GROUP                  0.0\n",
      "CODE                   0.0\n",
      "NAME                   0.0\n",
      "YEAR                   0.0\n",
      "DISEASE                0.0\n",
      "DISEASE_DESCRIPTION    0.0\n",
      "CASES                  0.0\n",
      "dtype: float64\n",
      "---------------------------------------\n",
      "Missing values percentage for every column in intro_df after cleaning and imputation:\n",
      "ISO_3_CODE     0.0\n",
      "COUNTRYNAME    0.0\n",
      "WHO_REGION     0.0\n",
      "YEAR           0.0\n",
      "DESCRIPTION    0.0\n",
      "INTRO          0.0\n",
      "dtype: float64\n",
      "---------------------------------------\n",
      "Missing values percentage for every column in schedule_df after cleaning and imputation:\n",
      "ISO_3_CODE               0.0\n",
      "COUNTRYNAME              0.0\n",
      "WHO_REGION               0.0\n",
      "YEAR                     0.0\n",
      "VACCINECODE              0.0\n",
      "VACCINE_DESCRIPTION      0.0\n",
      "SCHEDULEROUNDS           0.0\n",
      "TARGETPOP_DESCRIPTION    0.0\n",
      "GEOAREA                  0.0\n",
      "AGEADMINISTERED          0.0\n",
      "SOURCECOMMENT            0.0\n",
      "dtype: float64\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, df in dfs_new.items():\n",
    "    print(f\"Missing values percentage for every column in {name} after cleaning and imputation:\")\n",
    "    print(df.isna().mean()*100)\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ca53ac-6ed5-4c19-80d0-a24611892db8",
   "metadata": {},
   "source": [
    "### 3.11: Checking Datatypes of columns in all Cleaned dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12c12df8-9875-4913-9cbc-4c1b8acd7650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of every column in coverage_df after cleaning and imputation:\n",
      "GROUP                             object\n",
      "CODE                              object\n",
      "NAME                              object\n",
      "YEAR                               int32\n",
      "ANTIGEN                           object\n",
      "ANTIGEN_DESCRIPTION               object\n",
      "COVERAGE_CATEGORY                 object\n",
      "COVERAGE_CATEGORY_DESCRIPTION     object\n",
      "COVERAGE                         float64\n",
      "dtype: object\n",
      "---------------------------------------\n",
      "Data types of every column in incidence_df after cleaning and imputation:\n",
      "GROUP                   object\n",
      "CODE                    object\n",
      "NAME                    object\n",
      "YEAR                     int32\n",
      "DISEASE                 object\n",
      "DISEASE_DESCRIPTION     object\n",
      "DENOMINATOR             object\n",
      "INCIDENCE_RATE         float64\n",
      "dtype: object\n",
      "---------------------------------------\n",
      "Data types of every column in cases_df after cleaning and imputation:\n",
      "GROUP                   object\n",
      "CODE                    object\n",
      "NAME                    object\n",
      "YEAR                     int32\n",
      "DISEASE                 object\n",
      "DISEASE_DESCRIPTION     object\n",
      "CASES                  float64\n",
      "dtype: object\n",
      "---------------------------------------\n",
      "Data types of every column in intro_df after cleaning and imputation:\n",
      "ISO_3_CODE     object\n",
      "COUNTRYNAME    object\n",
      "WHO_REGION     object\n",
      "YEAR            int32\n",
      "DESCRIPTION    object\n",
      "INTRO          object\n",
      "dtype: object\n",
      "---------------------------------------\n",
      "Data types of every column in schedule_df after cleaning and imputation:\n",
      "ISO_3_CODE                object\n",
      "COUNTRYNAME               object\n",
      "WHO_REGION                object\n",
      "YEAR                       int32\n",
      "VACCINECODE               object\n",
      "VACCINE_DESCRIPTION       object\n",
      "SCHEDULEROUNDS           float64\n",
      "TARGETPOP_DESCRIPTION     object\n",
      "GEOAREA                   object\n",
      "AGEADMINISTERED           object\n",
      "SOURCECOMMENT             object\n",
      "dtype: object\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, df in dfs_new.items():\n",
    "    print(f\"Data types of every column in {name} after cleaning and imputation:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef57b0-c941-407d-882f-69f772de1dda",
   "metadata": {},
   "source": [
    "### 3.12: Creating Country, Antigen, Disease dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44644e96-6fe1-471f-b8a8-e20ecf6a5ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare country_df_clean with columns: 'iso_code', 'name'\n",
    "country_df_clean = coverage_df[['CODE', 'NAME']].drop_duplicates().rename(\n",
    "    columns={\n",
    "        'CODE': 'iso_code',\n",
    "        'NAME': 'name'\n",
    "    }\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Prepare antigen_df_clean with columns: 'antigen_id', 'description'\n",
    "antigen_df_clean = coverage_df[['ANTIGEN', 'ANTIGEN_DESCRIPTION']].drop_duplicates().rename(\n",
    "    columns={\n",
    "        'ANTIGEN': 'antigen_id',\n",
    "        'ANTIGEN_DESCRIPTION': 'description'\n",
    "    }\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Prepare disease_df_clean by combining unique diseases from incidence_df and cases_df\n",
    "disease_incidence = incidence_df[['DISEASE', 'DISEASE_DESCRIPTION']].drop_duplicates()\n",
    "disease_cases = cases_df[['DISEASE', 'DISEASE_DESCRIPTION']].drop_duplicates()\n",
    "\n",
    "disease_df_clean = pd.concat([disease_incidence, disease_cases]).drop_duplicates().rename(\n",
    "    columns={\n",
    "        'DISEASE': 'disease_code',\n",
    "        'DISEASE_DESCRIPTION': 'description'\n",
    "    }\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13433bf6-a7cb-4c80-8575-425f5b343621",
   "metadata": {},
   "source": [
    "### 3.13: Renaming columns in all Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbcd90a0-053a-4c1e-9ce5-4fd74bae4166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverage_df_clean\n",
    "coverage_df_clean = coverage_df_clean.rename(columns={\n",
    "    'CODE': 'country_code',\n",
    "    'YEAR': 'year',\n",
    "    'ANTIGEN': 'antigen_id',\n",
    "    'ANTIGEN_DESCRIPTION': 'antigen_description',\n",
    "    'COVERAGE_CATEGORY': 'coverage_category',\n",
    "    'COVERAGE_CATEGORY_DESCRIPTION': 'coverage_category_description',\n",
    "    'COVERAGE': 'coverage'\n",
    "})\n",
    "\n",
    "# incidence_df_clean\n",
    "incidence_df_clean = incidence_df_clean.rename(columns={\n",
    "    'CODE': 'country_code',\n",
    "    'YEAR': 'year',\n",
    "    'DISEASE': 'disease_code',\n",
    "    'DISEASE_DESCRIPTION': 'disease_description',\n",
    "    'DENOMINATOR': 'denominator',\n",
    "    'INCIDENCE_RATE': 'incidence_rate'\n",
    "})\n",
    "\n",
    "# cases_df_clean (reported_cases table)\n",
    "cases_df_clean = cases_df_clean.rename(columns={\n",
    "    'CODE': 'country_code',\n",
    "    'YEAR': 'year',\n",
    "    'DISEASE': 'disease_code',\n",
    "    'DISEASE_DESCRIPTION': 'disease_description',\n",
    "    'CASES': 'cases'\n",
    "})\n",
    "\n",
    "# intro_df_clean (vaccine_introduction table)\n",
    "intro_df_clean = intro_df_clean.rename(columns={\n",
    "    'ISO_3_CODE': 'country_code',\n",
    "    'WHO_REGION': 'who_region',\n",
    "    'YEAR': 'year',\n",
    "    'DESCRIPTION': 'description',\n",
    "    'INTRO': 'introduced'\n",
    "})\n",
    "\n",
    "# schedule_df_clean (vaccine_schedule table)\n",
    "schedule_df_clean = schedule_df_clean.rename(columns={\n",
    "    'ISO_3_CODE': 'country_code',\n",
    "    'WHO_REGION': 'who_region',\n",
    "    'YEAR': 'year',\n",
    "    'VACCINECODE': 'vaccine_code',\n",
    "    'VACCINE_DESCRIPTION': 'vaccine_description',\n",
    "    'SCHEDULEROUNDS': 'schedule_rounds',\n",
    "    'TARGETPOP_DESCRIPTION': 'target_population_description',\n",
    "    'GEOAREA': 'geoarea',\n",
    "    'AGEADMINISTERED': 'age_administered',\n",
    "    'SOURCECOMMENT': 'source_comment'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b26f22-b71c-4160-b866-c641ee77d3a6",
   "metadata": {},
   "source": [
    "### 3.14: Dropping Null values and Duplicate Values in Country, Antigen and Disease Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "522b04d8-d5a1-4387-8e9c-228c7a4f6056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values in key columns\n",
    "country_df_clean = country_df_clean.dropna(subset=['iso_code', 'name']).copy()\n",
    "antigen_df_clean = antigen_df_clean.dropna(subset=['antigen_id', 'description']).copy()\n",
    "disease_df_clean = disease_df_clean.dropna(subset=['disease_code', 'description']).copy()\n",
    "\n",
    "# Drop duplicate rows based on primary keys, keep first occurrence\n",
    "country_df_clean = country_df_clean.drop_duplicates(subset=['iso_code','name'], keep='first').copy()\n",
    "antigen_df_clean = antigen_df_clean.drop_duplicates(subset=['antigen_id'], keep='first').copy()\n",
    "disease_df_clean = disease_df_clean.drop_duplicates(subset=['disease_code'], keep='first').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ab5a85-439b-49a8-95b2-73046c597871",
   "metadata": {},
   "source": [
    "### 3.15: Dropping columns from all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "503d76a5-f383-43cd-9b1b-090cbada4b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df_clean = coverage_df_clean.drop(columns=['GROUP', 'NAME'], errors='ignore')\n",
    "\n",
    "incidence_df_clean = incidence_df_clean.drop(columns=['GROUP', 'NAME'], errors='ignore')\n",
    "\n",
    "cases_df_clean = cases_df_clean.drop(columns=['GROUP', 'NAME'], errors='ignore')\n",
    "\n",
    "intro_df_clean = intro_df_clean.drop(columns=['COUNTRYNAME'], errors='ignore')\n",
    "\n",
    "schedule_df_clean = schedule_df_clean.drop(columns=['COUNTRYNAME'], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2294878-8e41-4307-af0c-022bef64dd0d",
   "metadata": {},
   "source": [
    "To ensure that only relevant columns are loaded into the database and used in analysis, unnecessary columns were removed from each cleaned DataFrame.\n",
    "\n",
    "By applying the drop method with errors='ignore', these lines ensure that the specified columns are removed if present, and the process continues smoothly even if they are missing in certain DataFrames. This step helps maintain a clean and consistent schema across all datasets prior to database insertion and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee2e0c-06d7-428d-a2a7-c5a8add81003",
   "metadata": {},
   "source": [
    "### 3.16: Mapping 'introduced' column with boolean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ff87c6f-c40b-4a13-a023-3ddc01b8ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_df_clean['introduced'] = intro_df_clean['introduced'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad32770a-6059-4be9-9a7b-04afb7249783",
   "metadata": {},
   "source": [
    "## Step 4: Connecting to MySQL Database and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5498afcf-af6a-4ad1-a235-3bced44bb7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 241 records into country\n",
      "Inserted 69 records into antigen\n",
      "Inserted 13 records into disease\n",
      "Inserted 399858 records into coverage\n",
      "Inserted 84945 records into incidence\n",
      "Inserted 84869 records into reported_cases\n",
      "Inserted 138321 records into vaccine_introduction\n",
      "Inserted 8052 records into vaccine_schedule\n"
     ]
    }
   ],
   "source": [
    "# MySQL connection details\n",
    "username = 'root'\n",
    "password = 'root'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database = 'vaccination_data'\n",
    "\n",
    "engine = create_engine(f'mysql+pymysql://{username}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "tables_to_load = {\n",
    "    'country': country_df_clean,\n",
    "    'antigen': antigen_df_clean,\n",
    "    'disease': disease_df_clean,\n",
    "    'coverage': coverage_df_clean,\n",
    "    'incidence': incidence_df_clean,\n",
    "    'reported_cases': cases_df_clean,\n",
    "    'vaccine_introduction': intro_df_clean,\n",
    "    'vaccine_schedule': schedule_df_clean\n",
    "}\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"SET FOREIGN_KEY_CHECKS=0;\"))  # Disable FK checks to allow truncation\n",
    "    \n",
    "    # Truncate tables before loading to avoid duplicates\n",
    "    for table_name in tables_to_load.keys():\n",
    "        conn.execute(text(f\"TRUNCATE TABLE {table_name};\"))\n",
    "    \n",
    "    # Insert data with append mode, since schema exists\n",
    "    for table_name, df in tables_to_load.items():\n",
    "        if not df.empty:\n",
    "            df.to_sql(name=table_name, con=conn, if_exists='append', index=False)\n",
    "            print(f\"Inserted {len(df)} records into {table_name}\")\n",
    "        else:\n",
    "            print(f\"Skipping empty DataFrame for {table_name}\")\n",
    "    \n",
    "    conn.execute(text(\"SET FOREIGN_KEY_CHECKS=1;\"))  # Re-enable FK checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002f660-a00d-43f5-9b66-34f1f83a0202",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
